# ==============================================================================
# ECODRIVE QUERY API - ENVIRONMENT VARIABLES
# ==============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env file to version control!
# ==============================================================================

# ------------------------------------------------------------------------------
# API CONFIGURATION
# ------------------------------------------------------------------------------
API_TITLE="EcoDrive Query API"
API_VERSION="1.0.0"
API_DESCRIPTION="API for processing EcoDrive customer queries"

# ------------------------------------------------------------------------------
# EXTERNAL RAG API CONFIGURATION
# ------------------------------------------------------------------------------
# Base URL for the external RAG API (from Dify flow)
RAG_API_BASE_URL=https://rag-api.rpaclick.com

# API Key for authentication (Bearer token)
# Format: base64 encoded key from Dify flow
RAG_API_KEY=NjI3NjRkZjk5YjA4YjQxNTA5ZmY1ZjNiZTM5ZTIzNjI6NWRlMmI1MTc1MzRhMmFiMTFhZDM0ZjNmNDM1YTZhZmRjZDdkYTczNjlmZGUyOWY0ZWQxOTIzNzVkNjhlMzk2Yg==

# ------------------------------------------------------------------------------
# OPENAI CONFIGURATION
# ------------------------------------------------------------------------------
# Your OpenAI API key
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model for intent classification (supports JSON output)
OPENAI_MODEL_CLASSIFIER=gpt-3.5-turbo-0125

# Model for general chat responses
OPENAI_MODEL_CHAT=gpt-3.5-turbo

# Model for RAG responses (from Dify flow: o3-mini)
OPENAI_MODEL_RAG=o3-mini

# Temperature for LLM responses (0.0-1.0, higher = more creative)
OPENAI_TEMPERATURE=0.7

# ------------------------------------------------------------------------------
# COHERE CONFIGURATION (Optional - for reranking)
# ------------------------------------------------------------------------------
# Your Cohere API key (optional, used for reranking search results)
COHERE_API_KEY=your-cohere-api-key-here

# Cohere reranking model
COHERE_RERANK_MODEL=rerank-english-v3.0

# ------------------------------------------------------------------------------
# KNOWLEDGE BASE CONFIGURATION
# ------------------------------------------------------------------------------
# Comma-separated list of dataset IDs for knowledge retrieval
# These are the dataset IDs from your Dify flow
DATASET_IDS=Tq8Jp4RpkbgDrK98pz9NEc5CH8IhsE9PfikNQ1ETI5gj+p2Q+65q4REERHNHyJRA,TjJAeDHZMphWGal61GZzSt6xvpiuyfOcp8PPonj2Dsxx3euWhYimiD2pnYIOOPTA,jDJyD+kVRZbRiAzvsBlcEuW7K4rE38W55IXkia0U8ZLHT1FOBw8UvPuecsC859WO

# ------------------------------------------------------------------------------
# SERVER CONFIGURATION
# ------------------------------------------------------------------------------
# Host to bind the server to
HOST=0.0.0.0

# Port to run the server on
PORT=8000

# ------------------------------------------------------------------------------
# REDIS CONFIGURATION (Optional - for conversation storage)
# ------------------------------------------------------------------------------
# Redis URL for storing conversation history
# Leave empty to use in-memory storage (not recommended for production)
# Example: redis://localhost:6379/0
REDIS_URL=

# ------------------------------------------------------------------------------
# HTTP CLIENT CONFIGURATION
# ------------------------------------------------------------------------------
# Maximum number of retries for HTTP requests
HTTP_MAX_RETRIES=3

# Retry interval in milliseconds
HTTP_RETRY_INTERVAL=100

# Connect timeout in seconds
HTTP_CONNECT_TIMEOUT=30

# Read timeout in seconds
HTTP_READ_TIMEOUT=60

# ------------------------------------------------------------------------------
# NOTES
# ------------------------------------------------------------------------------
# 1. The RAG_API_KEY value above is from the Dify flow - replace if different
# 2. DATASET_IDS are placeholders from Dify - update with your actual dataset IDs
# 3. For production, consider using a secrets manager (AWS Secrets Manager, etc.)
# 4. Enable REDIS_URL for production to handle multiple instances
# 5. Knowledge base retrieval requires integration with a vector database
#    (Pinecone, Weaviate, ChromaDB, etc.) - see RAGService implementation
